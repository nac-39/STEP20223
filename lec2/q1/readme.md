# ハッシュテーブルの実装

## コードの実行

functional_test, performance_test が実行される。

```bash
$ cd STEP2023
$ python3 lec2/hash_tables.py
```

## 工夫したこと

### `Hash_Table.delete()`メソッドの実装

- `HashTable.buckets`には`Item`の先頭の要素だけが入っている。
- 消したい`Item`が先頭の時とそうでない時で処理を分ける。

### 再ハッシュ

要素数が bucket_size の 70%を超えたら拡張し、30%を下回っていたら縮小するようにした。
また、文字数が大きくなるとバケットサイズより少し大きい素数を探すのが遅くなってしまうので、次の二点を工夫した。

- 最初に 10000 個の素数を生成しておいて、二分探索で探す
- バケットサイズが用意していた素数の最大値より大きいなら、素数を使うのを諦めて奇数を使う

### ハッシュ関数の再実装

アナグラムになっている単語でハッシュ値が被らないようにした。
具体的には、「文字列の中での index 番目の素数 × 文字列の ord 値の和」で算出した：

```python
for i, k in enumerate(key):
    hash += many_primes[i] * ord(k)
```

## メモ

### `Hash_Table.delete()`メソッドの実装

- `HashTable.buckets`には`Item`の先頭の要素だけが入っている。
- 消したい`Item`が先頭の時とそうでない時で処理を分けないといけない。

## `performance_test`の結果

- 速度向上のために何もしてない時

<details>
<summary>結果</summary>

```plaintext
0 0.660312
1 1.095681
2 1.860802
3 2.435335
4 2.555958
5 3.276788
6 4.741652
7 5.478837
8 5.912355
9 6.473634
10 8.073731
11 8.562101
12 10.462486
13 10.963499
14 10.591143
15 11.758178
16 12.265143
17 14.718922
18 14.366009
19 16.448385
20 16.213876
21 17.160734
22 17.496969
23 19.433719
24 19.718676
25 20.826736
26 20.793536
27 23.289840
28 24.698754
29 23.879254
30 25.356521
31 27.880226
32 27.427562
33 29.225758
34 29.759982
35 29.586485
```

</details>

- `HashTable.buckets`のサイズを変えるようにした時  
  ~~逆に遅くなったが………？？~~ というより、特定の回（再ハッシュしている回）だけ遅くなっている！

<details>
<summary>結果</summary>

```plaintext
0 1.574800
1 2.920624
2 3.277485
3 5.196481
4 8.880142
5 1.988053
6 15.133866
7 2.756293
8 27.428764
9 3.131195
10 3.782188
11 49.801697
12 4.942622
13 6.474186
14 7.205083
15 7.929710
16 77.086919
17 7.354232
18 8.338592
19 9.283118
20 10.203802
21 13.038966
22 12.576525
23 127.356637
24 11.320420
25 12.338452
26 13.416994
27 13.978654
28 18.021652
29 16.503718
30 17.598146
31 19.312600
32 230.027086
33 14.765075
34 16.269958
35 17.153248
36 18.833983
37 20.147837
38 21.301383
39 21.458964
40 23.014750
41 24.059343
42 23.638033
43 24.302826
44 25.098593
```

</details>

- アナグラムのハッシュ値が被らないようにした時  
  ハッシュ値を、`素数[文字列の中でのインデックス] * ord(文字)` の和にした。こうすればアナグラムは同じハッシュ値にならないはず。

↓ 遅かったのは再ハッシュで素数を毎回 generate してるのが原因だった！！！ハッシュ値の計算は関係なかった
~~結果、特にテーブルが大きい時は速くなったけど、たまにめっちゃ遅い（なんで…？）。  
複数回実験しても同じ回が遅い。4, 6, 8, 11, 16, 23, 32、46、64 が遅い？。(4,6 は数が少ないからそこまででもないが)  
大体、 $2^n$ と $3\times 2^n$ が遅いっぽい？理由がよくわからない~~

<details>
<summary>結果</summary>

```plaintext
0 1.379983
1 2.490573
2 2.684923
3 4.549165
4 7.974051
5 0.274093
6 13.905000
7 0.275785
8 23.338869
9 0.380769
10 0.388566
11 38.289691
12 0.419022
13 0.457176
14 0.607773
15 0.590497
16 67.458955
17 0.633343
18 0.745134
19 0.751797
20 0.840171
21 0.961780
22 1.128246
23 116.049816
24 0.980553
25 1.171199
26 1.761864
27 1.383858
28 1.379058
29 1.837608
30 1.734522
31 2.419661
32 201.146356
33 1.377503
34 1.425056
35 1.550843
36 1.636029
37 1.982195
38 1.826021
39 1.904260
40 1.939725
41 2.184146
42 2.156168
43 2.340021
44 2.457412
45 2.597594
46 343.678992
47 2.039397
48 2.527741
49 2.241917
50 2.392599
51 2.457391
52 2.389686
53 2.691497
54 2.520032
55 2.780514
56 2.795000
57 2.964537
58 3.107452
59 3.231171
60 3.777948
61 3.679710
62 3.635393
63 3.412034
64 607.620085
65 3.340562
66 3.105187
67 3.179212
68 3.419848
69 3.523608
70 3.345745
71 4.489627
72 3.676390
73 3.534659
74 3.762265
75 4.328017
76 4.102805
77 4.526649
78 4.241772
79 4.571237
80 4.288331
81 4.374119
82 4.386912
83 4.442426
84 4.572307
85 5.327547
86 4.841195
87 4.952042
88 4.929631
89 5.067853
90 1962.188853
91 39.314810
92 4.672023
93 909.389683
94 4.742826
95 455.588204
96 5.041136
97 5.137390
98 5.247458
99 5.333102
```

</details>

- 素数を生成する関数`primes`を改善した時
  断然速くなった！！

<details>
<summary>結果</summary>

```plaintext
0 0.131298
1 0.158004
2 0.186028
3 0.237647
4 0.286811
5 0.184906
6 0.413406
7 0.359298
8 0.703268
9 0.328361
10 0.370849
11 1.267931
12 0.442423
13 0.503983
14 0.722041
15 0.742332
16 2.887016
17 1.291803
18 1.441874
19 1.071824
20 0.990875
21 1.586090
22 1.673859
23 3.525240
24 1.507034
25 1.357046
26 2.482481
27 1.524082
28 1.423917
29 1.326809
30 2.431628
31 1.536620
32 5.140300
33 1.300885
34 1.412610
35 1.497996
36 1.605793
37 1.821845
38 1.818870
39 1.905769
40 1.990089
41 2.189681
42 2.245235
43 2.330290
44 2.460676
45 2.484595
46 4.474739
47 2.969979
48 4.070705
49 2.804703
50 2.622367
51 2.748312
52 2.717447
53 2.841926
54 2.906711
55 3.035345
56 3.119200
57 3.230581
58 3.256665
59 3.411830
60 3.943410
61 3.556858
62 3.638418
63 4.435501
64 8.452487
65 2.910517
66 3.020918
67 2.900349
68 3.230105
69 3.457851
70 3.478480
71 3.694610
72 3.724685
73 3.992257
74 3.957014
75 4.070650
76 3.975122
77 4.181801
78 4.386662
79 4.487157
80 5.107931
81 5.059451
82 5.045653
83 5.057372
84 5.122145
85 5.894415
86 5.273295
87 5.282699
88 5.402869
89 5.497138
90 12.406971
91 4.412449
92 4.585580
93 4.563742
94 4.805976
95 4.827622
96 5.168595
97 5.334325
98 5.370967
99 5.596052
```

</details>

## 詰まった記録

- 参照渡し値渡し（Python の仕様がわからなくて詰まった）  
  hash_tables.py:L133 で「メモ: item には self.buckets[bucket_index]の値が入っているものとして考える。」このように書いているが、本当は item には参照が入っている。  
  例えば、while 文の中で item を次のように new_item で書き換えようとすると、

  ```python
  ...
  new_item = Item("key", "value", None)
  item = new_item
  ```

  この場合は`HashTable.buckets`の中に入っている`item`は書き換えられず、別の領域に新しく`item`が生成される。多分。

  でも、item の next だけを書き換える時は別の領域に`item`を作ることなく、`item.next`の値だけを書き換えている？からうまく動いている？

  どうやら、`item = hoge`と代入すると`item`の id は変わるが、`item.next = hoge`とすると`item`の id は変わらないらしい。

  C や Rust で書けたらここでは悩まないはず………；；

  参考： [https://www.javadrive.jp/python/userfunc/index3.html#section1](https://www.javadrive.jp/python/userfunc/index3.html#section1)
